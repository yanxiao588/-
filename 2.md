# main_fed.py
###### 数据管道: 将数据经过一系列处理步骤，从原始形式转换为最终可用于模型训练或推断的形式的过程。

###### PyTorch 的张量（tensor）：是 PyTorch 中用于表示多维数组或矩阵的数据类型，似于 NumPy 的数组，它支持在 CPU 或 GPU 上进行加速的数值计算，并且提供了丰富的操作方法和函数，方便进行各种深度学习任务的实现。

###### 标准化：一种常见的数据预处理步骤，作用有加速模型收敛，减少数据范围，减少数据的相关性，提高模型的鲁棒性

###### transforms.Compose() 接受一个包含多个图像变换操作的元组或列表，并将这些操作按顺序应用到输入图像上。这些变换操作可以是各种类型的，包括缩放、裁剪、归一化、随机裁剪等。
> 使用 Compose 的语法通常如下：
from torchvision import transforms
transformations = transforms.Compose([
transforms.Resize((224, 224)),
transforms.ToTensor(),
transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])在这个例子中，我们创建了一个变换序列，首先将图像大小调整为 224x224，然后将图像转换为 PyTorch 张量，最后对张量进行归一化。

###### MNIST：MNIST数据集是一个包含大量手写数字的集合。 在图像处理领域中，它是一个非常受欢迎的数据集。 经常被用于评估机器学习算法的性能。 MNIST是改进的标准与技术研究所数据库的简称。 MNIST 包含了一个由 70,000 个 28 x 28 的手写数字图像组成的集合，涵盖了从0到9的数字。
> dataset_train = datasets.MNIST('../data/mnist/', train=True, download=True, transform=trans_mnist)
datasets.MNIST：Pytorch的内置函数torchvision.datasets.MNIST，通过这个可以导入数据集。
train=True 代表我们读入的数据作为训练集（如果为true则从training.pt创建数据集，否则从test.pt创建数据集）
transform则是读入我们自己定义的数据预处理操作（ToTensor()：将图像数据转换为 PyTorch 张量的格式。Normalize()：对图像进行标准化处理，使得图像的像素值服从指定的均值和标准差。Resize()：调整图像尺寸。RandomHorizontalFlip() 和 RandomVerticalFlip()：随机水平或垂直翻转图像。RandomRotation()：随机旋转图像。
CenterCrop()：对图像进行中心裁剪。）
download=True则是当我们的根目录（root）下没有数据集时，便自动下载。

> rans_cifar=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])：创建一个数据转换管道，将图像转换为张量，并对图像进行归一化处理。这里使用了 transforms.Normalize() 对图像进行归一化，参数是均值和标准差，这些值是根据 CIFAR-10 数据集的特性预先计算得到的。

> net_glob = CNNCifar(args=args).to(args.device)：如果是CNN模型且数据集是CIFAR-10，就创建一个CNNCifar模型的实例，并将其移动到指定的设备上（GPU或CPU）。


> net_glob = CNNMnist(args=args).to(args.device)：如果是CNN模型且数据集是MNIST，就创建一个CNNMnist模型的实例，并将其移动到指定的设备上。

> MLP() 函数：创建一个多层感知机（MLP）模型实例，其参数如下：
dim_in：输入层的大小，即输入特征的数量。
dim_hidden：隐藏层的大小，即隐藏层神经元的数量。
dim_out：输出层的大小，即输出的类别数量（对于分类问题）或者输出的维度（对于回归问题）。



> m = max(int(args.frac * args.num_users), 1)：计算每轮训练中要参与训练的客户端数量。这里根据设定的分数 args.frac 和总客户端数量 args.num_users 来计算，最少选择一个客户端参与训练。

> idxs_users = np.random.choice(range(args.num_users), m, replace=False)：从总客户端数量中随机选择一定数量的客户端参与训练，返回的 idxs_users 是被选中的客户端的索引列表。

> local = LocalUpdate(args=args, dataset=dataset_train, idxs=dict_users[idx])：根据选定客户端的索引，创建一个本地更新对象 local，并传入所需的参数，包括全局参数、数据集和客户端数据索引。

> net_glob.eval()：将模型设置为评估（测试）模式。

> acc_train, loss_train = test_img(net_glob, dataset_train, args)：调用 test_img 函数对训练集进行评估，获取训练集的准确率 acc_train 和损失值 loss_train。该函数通常会对数据集进行预测并计算准确率和损失值。
###### 

###### 

###### 

###### 